<!doctype html>
<html>
<head>
<title> Augmented intelligence vs. artificial intelligence</title>
</head>
<body style="background-color:powderblue;">
<h1 style="color:brown;"><b>Augmented intelligence vs. artificial intelligence</b></h1>
<p>Some industry experts believe the term artificial intelligence is too closely linked to popular culture, and this has caused the general public to have improbable expectations about how AI will change the workplace and life in general. Some researchers and marketers hope the label <b>augmented intelligence</b>, which has a more neutral connotation, will help people understand that most implementations of AI will be weak and simply improve products and services.</p>
<p>The concept of <b>the technological singularity</b> -- a future ruled by an artificial superintelligence that far surpasses the human brain's ability to understand it or how it is shaping our reality --  remains within the realm of science fiction.
<h1 style="color:brown;"><b>Ethical use of artificial intelligence</b></h1>
<p>While AI tools present a range of new functionality for businesses, the use of artificial intelligence also raises ethical questions because, for better or worse, an AI system will reinforce what it has already learned.</p>
<p>This can be problematic because machine learning algorithms, which underpin many of the most advanced AI tools, are only as smart as the data they are given in training. Because a human being selects what data is used to train an AI program, the potential for machine learning bias is inherent and must be monitored closely.</p>
<p>Anyone looking to use machine learning as part of real-world, in-production systems needs to factor ethics into their AI training processes and strive to avoid bias. This is especially true when using AI algorithms that are inherently unexplainable in deep learning and generative adversarial network (GAN) applications.</p>
<p>Explainability is a potential stumbling block to using AI in industries that operate under strict regulatory compliance requirements. For example, financial institutions in the United States operate under regulations that require them to explain their credit-issuing decisions. When a decision to refuse credit is made by AI programming, however, it can be difficult to explain how the decision was arrived at because the AI tools used to make such decisions operate by teasing out subtle correlations between thousands of variables. When the decision-making process cannot be explained, the program may be referred to as black box AI.</p>
<p><a href="page2.html">Next Page</a></p>
</body>
</html>